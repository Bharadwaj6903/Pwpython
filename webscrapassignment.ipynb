{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0853ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1)\n",
    "Web scraping is an automatic method to obtain large amounts of \n",
    "data from websites. \n",
    "Most of this data is unstructured data in an HTML format which is then converted into \n",
    "structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "There are many different ways to perform \n",
    "web scraping to obtain data from websites. \n",
    "These include using online services, particular API’s \n",
    "or even creating your code for web scraping from scratch.\n",
    " Many large websites, like Google, Twitter, Facebook,\n",
    " StackOverflow, etc. have API’s that allow you to access\n",
    " their data in a structured format. \n",
    "This is the best option, but there are other sites that\n",
    " don’t allow users to access large amounts of data in a \n",
    "structured form or they are simply not that technologically advanced. \n",
    "In that situation, it’s best to use Web Scraping to scrape the website for data.\n",
    "\n",
    "\n",
    "WEB scrapping is used for price monitoring,market research,news monitoring,sentiment analysis,email marketing,monitoring e_commerce sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2)\n",
    "\n",
    "1)Pre-built Web Scrapers are previously created scrapers that you can download and run easily.\n",
    "These also have more advanced options that you can customize.\n",
    "2)Browser extensions Web Scrapers are extensions that can be added to your browser. \n",
    "These are easy to run as they are integrated with your browser.\n",
    "3)Software Web Scrapers can be downloaded and installed on your computer. These are more complex than Browser web scrapers, \n",
    "but they also have advanced features that are not limited by the scope of your browser.\n",
    "4_Cloud Web Scrapers run on the cloud, which is an off-site server mostly provided by the company that you buy the scraper from. \n",
    "These allow your computer to focus on other tasks as the computer resources are not required to scrape data from websites.\n",
    "5)Local Web Scrapers, on the other hand, run on your computer using local resources.\n",
    "So, if the Web scrapers require more CPU or RAM, then your computer will become slow and not be able to perform other tasks.\n",
    "6)Python can also be used for web scrapping beacause of BeautifulSoup module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a84e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3)\n",
    "\n",
    "Beautiful soup is a Python library that is highly suitable for Web Scraping. \n",
    "It creates a parse tree that can be used to extract data from HTML on a website. \n",
    "Beautiful soup also has multiple features for navigation, searching, and modifying these parse trees.\n",
    "Beautiful soup is used to get the data in a more beautiful version that the unformatted one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba82e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4\n",
    "flask is used to get the parse the data from html page of flipkart website in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5)\n",
    "\n",
    "Code pipeline and bean stack are the aws services used in this project.\n",
    "\n",
    "AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to\n",
    "release your software.\n",
    "You can quickly model and configure the different stages of a software release process. \n",
    "CodePipeline automates the steps required to release your software changes continuously. \n",
    "\n",
    "\n",
    "AWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and \n",
    "services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, or Docker on familiar servers such as\n",
    "Apache, Nginx, Passenger, and IIS. Elastic Beanstalk is a complete application management solution, and\n",
    "manages all infrastructure and platform tasks on your behalf.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
